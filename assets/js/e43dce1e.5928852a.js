"use strict";(self.webpackChunkedc_docs=self.webpackChunkedc_docs||[]).push([[9311],{3905:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>m});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},c=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=p(n),m=r,h=c["".concat(s,".").concat(m)]||c[m]||d[m]||o;return n?a.createElement(h,i(i({ref:t},u),{},{components:n})):a.createElement(h,i({ref:t},u))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=c;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=n[p];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}c.displayName="MDXCreateElement"},83142:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>d,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var a=n(87462),r=(n(67294),n(3905));const o={},i="Data plane module",l={unversionedId:"submodule/Connector/core/data-plane/README",id:"submodule/Connector/core/data-plane/README",title:"Data plane module",description:"Overview",source:"@site/docs/submodule/Connector/core/data-plane/README.md",sourceDirName:"submodule/Connector/core/data-plane",slug:"/submodule/Connector/core/data-plane/",permalink:"/edc-docs/docs/submodule/Connector/core/data-plane/",draft:!1,editUrl:"https://github.com/FraunhoferISST/edc-docs/tree/master/docs/submodule/Connector/core/data-plane/README.md",tags:[],version:"current",frontMatter:{}},s={},p=[{value:"Overview",id:"overview",level:2},{value:"Scope",id:"scope",level:2},{value:"Principles",id:"principles",level:2},{value:"Minimal state",id:"minimal-state",level:3},{value:"No transformation",id:"no-transformation",level:3},{value:"Do not reinvent the wheel",id:"do-not-reinvent-the-wheel",level:3},{value:"Flexible Deployment",id:"flexible-deployment",level:3},{value:"Extensible",id:"extensible",level:3},{value:"Design",id:"design",level:2},{value:"Data Plane Manager",id:"data-plane-manager",level:3},{value:"Pipeline Service",id:"pipeline-service",level:3},{value:"Pull Streaming",id:"pull-streaming",level:3}],u={toc:p};function d(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"data-plane-module"},"Data plane module"),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,"This module covers the Data Plane Framework (DPF), which is the entity in charge of performing the actual data transfer\nbetween consumer and provider. This DPF is developed in such a way that it can support a myriad of deployment\ntopologies."),(0,r.kt)("h2",{id:"scope"},"Scope"),(0,r.kt)("p",null,"The Data Plane Framework is designed to only work with:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"finite data transfers,"),(0,r.kt)("li",{parentName:"ul"},"small payload, latent non-finite transfers such as events.")),(0,r.kt)("p",null,"High-volume or latency-sensitive streaming (non-finite) data transfers should be handled by other implementations that\ndelegate to specialized third-party infrastructure such as Kafka."),(0,r.kt)("h2",{id:"principles"},"Principles"),(0,r.kt)("h3",{id:"minimal-state"},"Minimal state"),(0,r.kt)("p",null,"All state pertaining to a transfer process are maintained by the Control Plane as part of the ",(0,r.kt)("inlineCode",{parentName:"p"},"TransferProcess"),". The\nonly state that is maintained by the DPF is if a transfer process has been completed. This requires the Control Plane to\nissue retries in the event of failure."),(0,r.kt)("h3",{id:"no-transformation"},"No transformation"),(0,r.kt)("p",null,"The DPF is not an ETL tool. It does not contain any facilities for data transformations or processing. This is expected\nto be handled by the Control Plane as part of the provisioning state."),(0,r.kt)("h3",{id:"do-not-reinvent-the-wheel"},"Do not reinvent the wheel"),(0,r.kt)("p",null,"The DPF relies on existing data transfer technology such as S3, Azure Object Storage, FTP, etc. As a rule of thumb: the\nDPF should not contain any wire protocol implementations."),(0,r.kt)("h3",{id:"flexible-deployment"},"Flexible Deployment"),(0,r.kt)("p",null,"It must be possible to:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"deploy the DPF to a K8S cluster,"),(0,r.kt)("li",{parentName:"ul"},"deploy the DPF remotely from the Control Plane,"),(0,r.kt)("li",{parentName:"ul"},"deploy the DPF in the same process as the Control Plane for demo and testing purposes,")),(0,r.kt)("h3",{id:"extensible"},"Extensible"),(0,r.kt)("p",null,"The DPF is built using the EDC modularity and extensibility system."),(0,r.kt)("h2",{id:"design"},"Design"),(0,r.kt)("h3",{id:"data-plane-manager"},"Data Plane Manager"),(0,r.kt)("p",null,"The DataPlaneManager (DPM) enqueues ",(0,r.kt)("inlineCode",{parentName:"p"},"DataFlowRequest"),", which may originate from an ingress such as an HTTP endpoint. The\nqueue implementation will be a bounded, in-memory data structure that provides support for backpressure when the system\nis overloaded. However, since the queue is in-memory, the client control plane submitting the request will be\nresponsible for re-submitting a request in the event of failure."),(0,r.kt)("p",null,"The DPM implementation has a configurable number of workers that dequeue requests for processing (data transfer). This\nprocessing operation will complete asynchronously. When a result is returned, an entry for the process indicating\nsuccess or failure is made using extensible storage. This allows the Control Plane to query the DPF for the status (\nCOMPLETED or ERROR) of a process. No other state is maintained by the DPF."),(0,r.kt)("p",null,"The DPM also contains transfer methods that take a ",(0,r.kt)("inlineCode",{parentName:"p"},"DataSource")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"DataSink"),", respectively, These can be used to\nprovide an ad-hoc transfer source or destination. For example, user code may dequeue a message to memory and send it to\na destination using an ",(0,r.kt)("inlineCode",{parentName:"p"},"InputStreamDataSource")," that wraps the in-memory message. Similarly, user code may wish to\ntransfer data from a source to a provided ",(0,r.kt)("inlineCode",{parentName:"p"},"OutputStreamDataSink"),"."),(0,r.kt)("h3",{id:"pipeline-service"},"Pipeline Service"),(0,r.kt)("p",null,"When a DPM worker dequeues a request, it will delegate to the ",(0,r.kt)("inlineCode",{parentName:"p"},"transfer")," method of the ",(0,r.kt)("inlineCode",{parentName:"p"},"PipelineService"),"."),(0,r.kt)("p",null,"The implementation of this service is straightforward: it connects a sink with its source, both of which are\ninstantiated by extensible factories. This design allows for scalable, ",(0,r.kt)("em",{parentName:"p"},"n"),"-way data transfers since all data are\ndirectly streamed from its origin to the terminus."),(0,r.kt)("h3",{id:"pull-streaming"},"Pull Streaming"),(0,r.kt)("p",null,"The DPF design is based on a pull streaming model, i.e. a ",(0,r.kt)("inlineCode",{parentName:"p"},"DataSink")," pulls data from a ",(0,r.kt)("inlineCode",{parentName:"p"},"DataSource"),". This allows the\nsink to control the rate of transfer and potentially parallelize operation. Moreover, optimizations can be made such as\ncopy-in-place when the source and sink are the same infrastructure such as object storage hosted by a single cloud\nprovider."),(0,r.kt)("p",null,"Implementations may support random data access for parallel transfers of large files. For example, both AWS S3 and Azure\nObject Storage have facilities for ranged gets."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"DataSink")," implementations will provide the ability to configure parallel transfers, e.g. controlling the number of\nthreads to perform ranged gets."))}d.isMDXComponent=!0}}]);