<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/README">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.2.0">
<title data-rh="true">Serverless transfers in DPF | My Site</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://FraunhoferISST.github.io/edc-docs/docs/submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Serverless transfers in DPF | My Site"><meta data-rh="true" name="description" content="Decision"><meta data-rh="true" property="og:description" content="Decision"><link data-rh="true" rel="icon" href="/edc-docs/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://FraunhoferISST.github.io/edc-docs/docs/submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/"><link data-rh="true" rel="alternate" href="https://FraunhoferISST.github.io/edc-docs/docs/submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/" hreflang="en"><link data-rh="true" rel="alternate" href="https://FraunhoferISST.github.io/edc-docs/docs/submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/" hreflang="x-default"><link rel="stylesheet" href="/edc-docs/assets/css/styles.5bd81ef5.css">
<link rel="preload" href="/edc-docs/assets/js/runtime~main.b3ae5d38.js" as="script">
<link rel="preload" href="/edc-docs/assets/js/main.b883e2b3.js" as="script">
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#docusaurus_skipToContent_fallback">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/edc-docs/"><div class="navbar__logo"><img src="/edc-docs/img/icon.png" alt="My Site Logo" class="themedImage_ToTc themedImage--light_HNdA"><img src="/edc-docs/img/icon.png" alt="My Site Logo" class="themedImage_ToTc themedImage--dark_i4oU"></div><b class="navbar__title text--truncate"></b></a><a class="navbar__item navbar__link" href="/edc-docs/docs/">Docs</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/eclipse-dataspacecomponents/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><main class="docMainContainer_gTbr docMainContainerEnhanced_Uz_u"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Serverless transfers in DPF</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="decision">Decision<a class="hash-link" href="#decision" title="Direct link to heading">​</a></h2><p>Serverless mechanisms for data transfers are supported in DPF. Examples of serverless implementations include Azure Data Factory, a fully managed integration service that can be controlled through a REST API.
The Data Plane Framework uses a routing mechanism to either manage data transfer by itself (using pluggable sources and sinks), or delegate transfer to a pluggable service such as an extension for performing transfers with Azure Data Factory.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="rationale">Rationale<a class="hash-link" href="#rationale" title="Direct link to heading">​</a></h2><p>Serverless data transfer infrastructure is provided by major cloud providers and integration software vendors. For example, Azure Data Factory (ADF) offers a serverless way to copy data at scale in an optimised manner. As a managed service, it offers increased scalability and reduced operational load on the application when copying data.</p><p>Serverless offerings cannot replace DPF stream-based copy, since EDC users may not want a vendor dependency, and each serverless product supports a limited range of integrations. Serverless transfer can, however, be an optional module in DPF. DataFlowRequests can be routed to either serverless transfer or DPF source/sink streams, depending on rules to be defined, such as whether the serverless platform supports the source and sink, as well as transfer size.</p><p>Taking the example of Azure Data Factory, advantages of mature serverless integration platforms include:</p><ul><li>Optionally deploy Integration Runtime to access data within enterprise virtual network (or on-premises data).</li><li>High scalability and parallelism.</li><li>Optimized copy e.g. for blobs.</li><li>Built-in reliability mechanisms, checksumming, retry, monitoring.</li><li>80+ connectors, for example S3, Azure storage.</li><li>Flexible handling of many scenarios. For example, when copying from storage accounts, wildcards and hierarchy flattening.</li><li>Data transformation - not in scope at the moment, in the future we may want to land the data in the format the consumer requests it, such as Parquet for analytical applications.</li><li>Cost aligned to usage without overprovisioning.</li></ul><p>Limitations of serverless integration include:</p><ul><li>Complexity and additional failure point of adding an additional component.</li><li>Latency. As of February 2022, the <a href="https://azure.microsoft.com/en-us/support/legal/sla/data-factory/v1_2/" target="_blank" rel="noopener noreferrer">SLA for Data Factory</a> provides a 99.9% guarantee that activities start in less than 4 minutes. Though in practice, in our tests, runs started within a few seconds, the possible impact on end-to-end latency must be accounted for.</li><li>Cost may be variable and less predictable, which may complicate budgeting.</li></ul><p>DPF cannot perform all data transfers in serverless platforms. It therefore needs a routing mechanism to perform data transfers with streams, or delegate them to the serverless platform. Besides the obvious scenario of a source or sink type that the platform does not support, DPF could use various approaches for this routing:</p><ul><li>Request-based: the DataFlowRequest could contain attributes indicating which approach is preferred. An interactive application which transfers small payloads would favor low latency and benefit little from the high scalability of serverless platforms. By setting relevant attributes in the request, it could signal DPF to favour not using a serverless platform in this case.</li><li>Rule-based: DPF could estimate the size of the transfer, and perform &quot;small&quot; transfers using streams, and delegate &quot;large&quot; transfers to serverless platforms. Other drivers could be system load and network bandwidth use.</li></ul><p>A related topic is routing among several serverless platforms, if several are enabled on an EDC deployment. However, in practice EDC users will probably integrate with the native offering of their cloud provider, so this can be dealt later as needed.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="spike">Spike<a class="hash-link" href="#spike" title="Direct link to heading">​</a></h2><p>We built a <a href="https://github.com/agera-edc/DataSpaceConnector/pull/112" target="_blank" rel="noopener noreferrer">spike</a> in a forked repository to showcase the simplest possible use of ADF, to copy data between two storage accounts.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="structure">Structure<a class="hash-link" href="#structure" title="Direct link to heading">​</a></h3><ul><li>The DPF server code was modified to add an extension that routes data flow requests to ADF if the source and the destination are both Azure Blob storage (this is illustrative, as ADF would also allow other types of source and destination).</li><li>An Azure Key Vault (AKV) is deployed in the provider&#x27;s domain to manage transient secrets including the storage account key for both source and destination storage accounts, which are passed within the data flow request.</li><li>An Azure Data Factory instance is deployed in the provider&#x27;s domain, with read access to Azure Key Vault secrets.</li></ul><p>The DPF extension for ADF provisions, for each transfer request:</p><ul><li>Two AKV secrets, one for each of the source and destination storage account key (as passed in the data flow request).</li><li>Two ADF linked services, one for each of the source and destination storage accounts. Each linked service is linked to the corresponding AKV secret.</li><li>Two ADF datasets, one for each of the source and destination. Each dataset is linked to the corresponding linked service.</li><li>One ADF pipeline, containing a single activity to copy data from source to destination. The activity is linked to both datasets.</li><li>One ADF pipeline run.</li></ul><p>The pipeline run is asynchronous, and the DPF extension should use a state machine to regularly poll for completion. In the spike, for simplicity, we implemented busy polling to provide a synchronous implementation.</p><p>When using Data Factory Studio, note that pipelines created through the REST API do not appear in the pipeline designer (for manual editing). However, the runs of those pipelines do appear in the Monitor tab.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="walkthrough">Walkthrough<a class="hash-link" href="#walkthrough" title="Direct link to heading">​</a></h3><p>The DPF <code>PipelineService</code> is responsible for looking up source and sink stream implementation and using them to effect a transfer. That service was extended to pass the request to a <code>AzureDataFactoryTransferService</code> if the source and destination are both blobs. This implementation violates Single Responsibility Possibility for the sake of simplicity in the spike.</p><p>The <code>AzureDataFactoryTransferService</code> uses the Azure Resource Manager SDK using a service principal. This requires the<code>AZURE_TENANT_ID</code>, <code>AZURE_SUBSCRIPTION_ID</code>,  <code>AZURE_CLIENT_ID</code> and<code>AZURE_CLIENT_SECRET</code> environment variables to be set.</p><p>The <code>AzureDataFactoryTransferService</code> provisions the AKV secrets and ADF pipeline, and then waits for the pipeline to enter a terminal state.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="results">Results<a class="hash-link" href="#results" title="Direct link to heading">​</a></h3><p>The implementation of a DPF transfer was straightforward using the ADF SDK. Run details are available using a UI. In this test run, a 100 MiB blob was copied in 9 seconds with 10 resp. 12 parallel connections on the source and destinations, and the data was verified using checksums.</p><p><img loading="lazy" alt="ADF run" src="/edc-docs/assets/images/adf-run-details-b1a8a9e25fc13fbabe56da3f5e326232.png" width="1626" height="1160" class="img_ev3q"></p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="deployment">Deployment<a class="hash-link" href="#deployment" title="Direct link to heading">​</a></h3><p>Run the following script to deploy Azure resources. Resource names can be adapted by editing the script.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docs/developer/decision-records/2022-03-01-serverless-transfers/create-resources-and-run-server.sh</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Once the DPF server is running, all resources have been deployed.</p><p>You can then run integration test <code>org.eclipse.dataspaceconnector.azure.dataplane.azurestorage.AzureDataFactoryCopyIntegrationTest</code>.</p><p>In Azure portal, navigate to the data factory instance and open Data Factory Studio. In the Monitor tab, you can view details for the run.</p><p>You can also use DPF server that is run by the script, to start a transfer between any storage accounts with curl or Postman.</p><div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">curl</span><span class="token plain"> http://localhost:8181/control/transfer -H </span><span class="token string" style="color:#e3116c">&quot;Content-Type: application/json&quot;</span><span class="token plain"> --data </span><span class="token string" style="color:#e3116c">&#x27;{</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;id&quot;: &quot;9033DE3C-711A-4803-8AB8-489AC795D82D&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;edctype&quot;: &quot;dataspaceconnector:dataflowrequest&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;processId&quot;: &quot;1647468C-2A0F-4DB1-B45C-08DB3EAF7AD9&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;sourceDataAddress&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;account&quot;: &quot;&lt;ACCOUNTNAME&gt;&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;type&quot;: &quot;AzureStorageBlobData&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;container&quot;: &quot;&lt;CONTAINERNAME&gt;&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;blob&quot;: &quot;&lt;BLOBNAME&gt;&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;sharedKey&quot;: &quot;&lt;SHAREDKEY&gt;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    },</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    &quot;destinationDataAddress&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        &quot;properties&quot;: {</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;account&quot;: &quot;&lt;ACCOUNTNAME&gt;&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;type&quot;: &quot;AzureStorageBlobData&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;container&quot;: &quot;&lt;CONTAINERNAME&gt;&quot;,</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">            &quot;sharedKey&quot;: &quot;&lt;SHAREDKEY&gt;&quot;</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">        }</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">    }</span><br></span><span class="token-line" style="color:#393A34"><span class="token string" style="color:#e3116c">}&#x27;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg class="copyButtonIcon_y97N" viewBox="0 0 24 24"><path d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg class="copyButtonSuccessIcon_LjdS" viewBox="0 0 24 24"><path d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/FraunhoferISST/edc-docs/tree/master/docs/submodule/Connector/docs/developer/decision-records/2022-03-01-serverless-transfers/README.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#decision" class="table-of-contents__link toc-highlight">Decision</a></li><li><a href="#rationale" class="table-of-contents__link toc-highlight">Rationale</a></li><li><a href="#spike" class="table-of-contents__link toc-highlight">Spike</a><ul><li><a href="#structure" class="table-of-contents__link toc-highlight">Structure</a></li><li><a href="#walkthrough" class="table-of-contents__link toc-highlight">Walkthrough</a></li><li><a href="#results" class="table-of-contents__link toc-highlight">Results</a></li><li><a href="#deployment" class="table-of-contents__link toc-highlight">Deployment</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items clean-list"></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 My Project,  built with Fraunhofer ISST.</div></div></div></footer></div>
<script src="/edc-docs/assets/js/runtime~main.b3ae5d38.js"></script>
<script src="/edc-docs/assets/js/main.b883e2b3.js"></script>
</body>
</html>