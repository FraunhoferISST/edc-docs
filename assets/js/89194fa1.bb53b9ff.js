"use strict";(self.webpackChunkedc_docs=self.webpackChunkedc_docs||[]).push([[3304],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},o=Object.keys(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(r=0;r<o.length;r++)n=o[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),c=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=c(e.components);return r.createElement(s.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,p=i(e,["components","mdxType","originalType","parentName"]),u=c(n),m=a,f=u["".concat(s,".").concat(m)]||u[m]||d[m]||o;return n?r.createElement(f,l(l({ref:t},p),{},{components:n})):r.createElement(f,l({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var o=n.length,l=new Array(o);l[0]=u;var i={};for(var s in t)hasOwnProperty.call(t,s)&&(i[s]=t[s]);i.originalType=e,i.mdxType="string"==typeof e?e:a,l[1]=i;for(var c=2;c<o;c++)l[c]=n[c];return r.createElement.apply(null,l)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},83220:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var r=n(87462),a=(n(67294),n(3905));const o={},l="Improve the file transfer",i={unversionedId:"submodule/Connector/samples/file-transfer-cloud/README",id:"submodule/Connector/samples/file-transfer-cloud/README",title:"Improve the file transfer",description:"So far we have performed a file transfer on a local machine using the Eclipse Dataspace Connector. While that is already",source:"@site/docs/submodule/Connector/samples/05-file-transfer-cloud/README.md",sourceDirName:"submodule/Connector/samples/05-file-transfer-cloud",slug:"/submodule/Connector/samples/file-transfer-cloud/",permalink:"/edc-docs/docs/submodule/Connector/samples/file-transfer-cloud/",draft:!1,editUrl:"https://github.com/FraunhoferISST/edc-docs/tree/master/docs/submodule/Connector/samples/05-file-transfer-cloud/README.md",tags:[],version:"current",frontMatter:{}},s={},c=[{value:"Setup local dev environment",id:"setup-local-dev-environment",level:2},{value:"Deploy cloud resources",id:"deploy-cloud-resources",level:2},{value:"Update connector config",id:"update-connector-config",level:2},{value:"Update data seeder",id:"update-data-seeder",level:2},{value:"Bringing it all together",id:"bringing-it-all-together",level:2},{value:"1. Boot connectors",id:"1-boot-connectors",level:3},{value:"2. Retrieve provider Contract Offers",id:"2-retrieve-provider-contract-offers",level:3},{value:"3. Negotiate Contract",id:"3-negotiate-contract",level:4},{value:"4. Get Contract Agreement Id",id:"4-get-contract-agreement-id",level:4},{value:"5. Transfer Data",id:"5-transfer-data",level:4},{value:"6. Deprovision resources",id:"6-deprovision-resources",level:4}],p={toc:c};function d(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,r.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"improve-the-file-transfer"},"Improve the file transfer"),(0,a.kt)("p",null,"So far we have performed a file transfer on a local machine using the Eclipse Dataspace Connector. While that is already\ngreat progress, it probably won't be much use in a real-world production application."),(0,a.kt)("p",null,'This chapter improves on this by moving the file transfer "to the cloud". What we mean by that is that instead of\nreading and writing the file from/to the disk, we will now:'),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"read the source from an Azure Storage,"),(0,a.kt)("li",{parentName:"ul"},"put the destination file into an AWS S3 Bucket.")),(0,a.kt)("h2",{id:"setup-local-dev-environment"},"Setup local dev environment"),(0,a.kt)("p",null,"Before we get into the nitty-gritty of cloud-based data transfers, we need to set up cloud resources. While we could do\nthat manually clicking through the Azure and AWS portals, there are simply more elegant solutions around. We use\nHashicorp Terraform for deployment and maintenance."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"You will need an active Azure Subscription and an AWS Account with root-user/admin access! Both platforms offer free tiers, so no immediate cost incurs.")),(0,a.kt)("p",null,"Also, you will need to be logged in to your Azure CLI as well as AWS CLI by entering the following commands in a shell:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"az login\naws configure\n")),(0,a.kt)("p",null,"The deployment scripts will provision all resources in Azure and AWS (that's why you need to be logged in to the CLIs)\nand store all access credentials in an Azure Vault (learn more ",(0,a.kt)("a",{parentName:"p",href:"https://azure.microsoft.com/de-de/services/key-vault/#product-overview"},"here"),")."),(0,a.kt)("h2",{id:"deploy-cloud-resources"},"Deploy cloud resources"),(0,a.kt)("p",null,"It's as simple as running the main terraform script:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd samples/05-file-transfer-cloud/terraform \nterraform init\nterraform apply\n")),(0,a.kt)("p",null,'it will prompt you to enter a unique name, which will serve as prefix for many resources both in Azure and in AWS. Then,\nenter "yes" and let terraform works its magic.'),(0,a.kt)("p",null,"It shouldn't take more than a couple of minutes, and when it's done it will log the ",(0,a.kt)("inlineCode",{parentName:"p"},"client_id"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"tenant_id"),"\n, ",(0,a.kt)("inlineCode",{parentName:"p"},"vault-name"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"storage-container-name")," and ",(0,a.kt)("inlineCode",{parentName:"p"},"storage-account-name"),"."),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"Take a note of these values!")),(0,a.kt)("p",null,"Download the certificate used to authenticate the generated service principal against Azure Active Directory:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"terraform output -raw certificate | base64 --decode > cert.pfx\n")),(0,a.kt)("h2",{id:"update-connector-config"},"Update connector config"),(0,a.kt)("p",null,(0,a.kt)("em",{parentName:"p"},"Do the following for both the consumer's and the provider's ",(0,a.kt)("inlineCode",{parentName:"em"},"config.properties"),"!")),(0,a.kt)("p",null,"Let's modify the following config values to the connector configuration ",(0,a.kt)("inlineCode",{parentName:"p"},"config.properties")," and insert the values that\nterraform logged before:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-properties"},"edc.vault.clientid=<client_id>\nedc.vault.tenantid=<tenant_id>\nedc.vault.certificate=<path_to_pfx_file>\nedc.vault.name=<vault-name>\n")),(0,a.kt)("h2",{id:"update-data-seeder"},"Update data seeder"),(0,a.kt)("p",null,"Put the storage account name into the ",(0,a.kt)("inlineCode",{parentName:"p"},"DataAddress")," builders within the ",(0,a.kt)("inlineCode",{parentName:"p"},"CloudTransferExtension")," class."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'DataAddress.Builder.newInstance()\n   .type("AzureStorage")\n   .property("account", "<storage-account-name>")\n   .property("container", "src-container")\n   .property("blobname", "test-document.txt")\n   .keyName("<storage-account-name>-key1")\n   .build();\n')),(0,a.kt)("h2",{id:"bringing-it-all-together"},"Bringing it all together"),(0,a.kt)("h3",{id:"1-boot-connectors"},"1. Boot connectors"),(0,a.kt)("p",null,"While we have deployed several cloud resources in the previous chapter, the connectors themselves still run locally.\nThus, we can simply rebuild and run them:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"./gradlew clean build\njava -Dedc.fs.config=samples/05-file-transfer-cloud/consumer/config.properties -jar samples/05-file-transfer-cloud/consumer/build/libs/consumer.jar\n# in another terminal window:\njava -Dedc.fs.config=samples/05-file-transfer-cloud/provider/config.properties -jar samples/05-file-transfer-cloud/provider/build/libs/provider.jar\n")),(0,a.kt)("h3",{id:"2-retrieve-provider-contract-offers"},"2. Retrieve provider Contract Offers"),(0,a.kt)("p",null,"To request data offers from the provider, run:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X GET -H 'X-Api-Key: password' http://localhost:9191/api/control/catalog?provider=http://localhost:8282/api/v1/ids/data\n")),(0,a.kt)("h4",{id:"3-negotiate-contract"},"3. Negotiate Contract"),(0,a.kt)("p",null,"To negotiate a contract copy one of the contract offers into the statement below and execute it. At the time of writing\nit is only possible to negotiate an ",(0,a.kt)("em",{parentName:"p"},"unchanged")," contract, so counter offers are not supported."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'curl --location --request POST \'http://localhost:9192/api/v1/management/contractnegotiations\' \\\n--header \'X-API-Key: password\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'{\n  "connectorId": "provider",\n  "connectorAddress": "http://localhost:8282/api/v1/ids/data",\n  "protocol": "ids-multipart",\n  "offer": {\n    "offerId": "1:3a75736e-001d-4364-8bd4-9888490edb58",\n    "assetId": "1",\n    "policy": { <Copy one of the policy from contractoffer.json file in samples/04.0-file-transfer> }\n  }\n}\'\n')),(0,a.kt)("p",null,"The EDC will answer with the contract negotiation id. This id will be used in step 4."),(0,a.kt)("h4",{id:"4-get-contract-agreement-id"},"4. Get Contract Agreement Id"),(0,a.kt)("p",null,"To get the contract agreement id insert the negotiation id into the following statement end execute it."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X GET -H 'X-Api-Key: password' \"http://localhost:9192/api/v1/management/contractnegotiations/{negotiationId}\"\n")),(0,a.kt)("p",null,"The EDC will return the current state of the contract negotiation. When the negotiation is completed successfully (this may take a few seconds),\nthe response will also contain an agreement id, that is required in the next step."),(0,a.kt)("h4",{id:"5-transfer-data"},"5. Transfer Data"),(0,a.kt)("p",null,"To initiate the data transfer, execute the statement below. Please take care of setting the contract agreement id obtained at previous step."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'curl --location --request POST \'http://localhost:9192/api/v1/management/transferprocess\' \\\n--header \'X-API-Key: password\' \\\n--header \'Content-Type: application/json\' \\\n--data-raw \'\n{\n  "connectorAddress": "http://localhost:8282/api/v1/ids/data",\n  "protocol": "ids-multipart",\n  "connectorId": "consumer",\n  "assetId": "1",\n  "contractId": "<ContractAgreementId>",\n  "dataDestination": {\n    "properties": {\n      "type": "AmazonS3",\n      "region": "us-east-1"\n    },\n    "type": "AmazonS3"\n  },\n  "managedResources": true,\n  "transferType": {\n    "contentType": "application/octet-stream",\n    "isFinite": true\n  }\n}\'\n')),(0,a.kt)("p",null,"This command will return a transfer process id which will used to request the deprovisioning of the resources."),(0,a.kt)("h4",{id:"6-deprovision-resources"},"6. Deprovision resources"),(0,a.kt)("p",null,"Deprovisioning is not necessary per se, but it will do some cleanup, delete the temporary AWS role and the S3 bucket, so\nit's generally advisable to do it."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"curl -X POST -H 'X-Api-Key: password' \"http://localhost:9192/api/v1/management/transferprocess/{transferProcessId}/deprovision\"\n")),(0,a.kt)("p",null,"Finally, run terraform to clean-up the vault and other remaining stuffs:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"cd samples/05-file-transfer-cloud/terraform \nterraform destroy\n")),(0,a.kt)("hr",null),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"/edc-docs/docs/submodule/Connector/samples/04.3-open-telemetry/"},"Previous Chapter")))}d.isMDXComponent=!0}}]);